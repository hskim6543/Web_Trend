{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait as wait\n",
    "from selenium.webdriver.common.by import By\n",
    "import pickle as pk\n",
    "from collections import OrderedDict\n",
    "\n",
    "driver = wd.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(start):\n",
    "    ##계정명, 구독자 수 crawling\n",
    "    driver.get(start)\n",
    "    wait(driver, 10).until(EC.presence_of_element_located((By.ID,\"channel-info\")))\n",
    "    count = driver.find_element_by_css_selector(\"#subscriber-count\")\n",
    "    name = driver.find_element_by_css_selector(\"#channel-title\").text\n",
    "    try:\n",
    "        subs = int(count.text.split(\" \")[-1].replace(\"명\",\"\").replace(\",\",\"\"))\n",
    "        result[name] = subs\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    ## 관련 채널 계정명, 주소 crawling\n",
    "    relates = driver.find_elements_by_tag_name(\"ytd-mini-channel-renderer\")\n",
    "    links = []\n",
    "    for x in relates:\n",
    "        link_rel = x.find_element_by_tag_name(\"a\").get_attribute(\"href\")\n",
    "        name_rel = x.find_element_by_tag_name(\"span\").text\n",
    "        links.append((name_rel,link_rel))\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling Depth를 입력하시오.5\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    f_t = open(\"todo.pk\",\"rb\")\n",
    "    todo = pk.load(f_t)\n",
    "    f_d = open(\"done.pk\",\"rb\")\n",
    "    result = pk.load(f_d)\n",
    "    f_t.close()\n",
    "    f_d.close()\n",
    "    \n",
    "except:\n",
    "    result = {}\n",
    "    todo = crawl(\"https://www.youtube.com/user/BuzzFeedVideo\")\n",
    "\n",
    "depth = 1\n",
    "depth_f = False\n",
    "Depth = int(input(\"Crawling Depth를 입력하시오.\"))\n",
    "\n",
    "while len(todo)>0:\n",
    "    try:\n",
    "\n",
    "        name_rel, link_rel = todo.pop(0)\n",
    "        \n",
    "        depth += 1\n",
    "        print(depth)\n",
    "        \n",
    "        for x in crawl(link_rel):\n",
    "            if x[0] not in result:\n",
    "                if depth >= Depth:\n",
    "                    depth_f = True\n",
    "                    continue\n",
    "                    \n",
    "                else:\n",
    "                    todo.insert(0,x)\n",
    "                    todo = list(OrderedDict.fromkeys(todo))\n",
    "                    \n",
    "        if depth_f == True:\n",
    "            depth -= 1\n",
    "            depth_f = False\n",
    "            \n",
    "    except:\n",
    "        if name_rel not in result and (name_rel,link_rel) not in todo:\n",
    "            todo.insert(0,(name_rel,link_rel))\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "f = open(\"todo.pk\",\"wb\")\n",
    "pk.dump(todo, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"done.pk\",\"wb\")\n",
    "pk.dump(result, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(\"result.csv\",\"w\") as csvfileOut:\n",
    "    writer = csv.writer(csvfileOut,delimiter = ',',quotechar='\"')\n",
    "    writer.writerow(['name','link','subscribers'])\n",
    "    writer.writerows('done.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "f = open('done.pk', 'rb')\n",
    "import pickle as pk\n",
    "done = pk.load(f)\n",
    "f.close()\n",
    "with codecs.open('result2.csv', 'w', 'utf-8') as csvfileOut:\n",
    "    csvfileOut.write(\"{},{},{}\\n\".format('name', 'link', 'subscribers'))\n",
    "    for k,v in done.items():\n",
    "        csvfileOut.write(\"{},{},{}\\n\".format(k, '', v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.11.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "selenium.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
